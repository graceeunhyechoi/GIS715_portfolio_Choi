{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[85]:28: DtypeWarning: Columns (0,16,20,22,24,25,26,27,28,29,34,35,36,37,38,39,40,41,43,44,46,47,51,52,55,56,57,61,62,63,64,65,66,67,68,71,72,73,75,76,77,79,80,81,82,83,84,85,86,88,89,92,93,94,95,96) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Report:</th>\n",
       "      <th>Bulk Mentions Download</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "      <th>Unnamed: 20</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "      <th>Unnamed: 24</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "      <th>Unnamed: 28</th>\n",
       "      <th>Unnamed: 29</th>\n",
       "      <th>Unnamed: 30</th>\n",
       "      <th>Unnamed: 31</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>Unnamed: 33</th>\n",
       "      <th>Unnamed: 34</th>\n",
       "      <th>Unnamed: 35</th>\n",
       "      <th>Unnamed: 36</th>\n",
       "      <th>Unnamed: 37</th>\n",
       "      <th>Unnamed: 38</th>\n",
       "      <th>Unnamed: 39</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 59</th>\n",
       "      <th>Unnamed: 60</th>\n",
       "      <th>Unnamed: 61</th>\n",
       "      <th>Unnamed: 62</th>\n",
       "      <th>Unnamed: 63</th>\n",
       "      <th>Unnamed: 64</th>\n",
       "      <th>Unnamed: 65</th>\n",
       "      <th>Unnamed: 66</th>\n",
       "      <th>Unnamed: 67</th>\n",
       "      <th>Unnamed: 68</th>\n",
       "      <th>Unnamed: 69</th>\n",
       "      <th>Unnamed: 70</th>\n",
       "      <th>Unnamed: 71</th>\n",
       "      <th>Unnamed: 72</th>\n",
       "      <th>Unnamed: 73</th>\n",
       "      <th>Unnamed: 74</th>\n",
       "      <th>Unnamed: 75</th>\n",
       "      <th>Unnamed: 76</th>\n",
       "      <th>Unnamed: 77</th>\n",
       "      <th>Unnamed: 78</th>\n",
       "      <th>Unnamed: 79</th>\n",
       "      <th>Unnamed: 80</th>\n",
       "      <th>Unnamed: 81</th>\n",
       "      <th>Unnamed: 82</th>\n",
       "      <th>Unnamed: 83</th>\n",
       "      <th>Unnamed: 84</th>\n",
       "      <th>Unnamed: 85</th>\n",
       "      <th>Unnamed: 86</th>\n",
       "      <th>Unnamed: 87</th>\n",
       "      <th>Unnamed: 88</th>\n",
       "      <th>Unnamed: 89</th>\n",
       "      <th>Unnamed: 90</th>\n",
       "      <th>Unnamed: 91</th>\n",
       "      <th>Unnamed: 92</th>\n",
       "      <th>Unnamed: 93</th>\n",
       "      <th>Unnamed: 94</th>\n",
       "      <th>Unnamed: 95</th>\n",
       "      <th>Unnamed: 96</th>\n",
       "      <th>Unnamed: 97</th>\n",
       "      <th>Unnamed: 98</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brand:</td>\n",
       "      <td>AS - Plant pests - 12/9/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From:</td>\n",
       "      <td>Wed Jan 01 00:00:00 UTC 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To:</td>\n",
       "      <td>Sun Jan 02 00:00:00 UTC 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Label:</td>\n",
       "      <td>3 yr Tuta Abs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Report:        Bulk Mentions Download  ... Unnamed: 97 Unnamed: 98\n",
       "0  Brand:  AS - Plant pests - 12/9/2021  ...         NaN         NaN\n",
       "1   From:  Wed Jan 01 00:00:00 UTC 2020  ...         NaN         NaN\n",
       "2     To:  Sun Jan 02 00:00:00 UTC 2022  ...         NaN         NaN\n",
       "3  Label:                 3 yr Tuta Abs  ...         NaN         NaN\n",
       "4     NaN                           NaN  ...         NaN         NaN\n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Read the data and store it in a pandas dataframe, df.  \n",
    "# A data frame is a 2-dimensional data structure.  \n",
    "projectDir = r'C:\\Users\\echoi4\\Desktop\\esterArcGISProject-20230428T013544Z-001\\esterArcGISProject' ## Replace with your data directory\n",
    "try:\n",
    "    # When working inside ArcGIS Pro,\n",
    "    # use the project name \"CURRENT\"\n",
    "    aprx = arcpy.mp.ArcGISProject(\"CURRENT\")\n",
    "except:\n",
    "    # When working outside of ArcGIS Pro,\n",
    "    # use the project full path file name.\n",
    "    aprx = arcpy.mp.ArcGISProject(project_dir + \"/estherArcGISProject.aprx\")\n",
    "    \n",
    "workingDir = projectDir + \"\\outputFreq\\\\\"\n",
    "fileGDB = projectDir + '\\esterArcGISProject.gdb\\\\'\n",
    "visDir = workingDir + '\\picsFreq\\\\'\n",
    "\n",
    "# Create output directories if they don't already exist.\n",
    "dirs = [workingDir, visDir]\n",
    "for d in dirs:\n",
    "    if not os.path.exists(d):\n",
    "        os.mkdir(d)\n",
    "\n",
    "myData = projectDir + '\\essie2.csv' #'tuta_absoluta.csv' \n",
    "df = pd.read_csv(myData)\n",
    "\n",
    "# Print the first 5 records to get a feel for the data.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Number', 'Page Type', 'Country', 'Year', 'Full Text'], dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What fields does the data have?\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many columns and rows does the data have?\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['United States', 'Australia', 'Canada', 'Netherlands',\n",
       "       'United Kingdom', 'Poland', 'Japan', 'New Zealand', 'Italy',\n",
       "       'Vietnam', 'Republic of Ireland', 'Finland', 'Croatia', 'Israel',\n",
       "       'Germany', 'The Bahamas', 'Brazil', 'Russia', 'Norway',\n",
       "       'Indonesia', 'South Africa', 'Pakistan', 'India',\n",
       "       'Republic of Serbia', 'Argentina', 'Singapore', 'Sweden',\n",
       "       'Colombia', 'Mexico', 'Gibraltar', 'Venezuela'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which countries are there in the \"Country\" field?\n",
    "# The Series method named unique returns a Numpy array containing the unique values in a series. \n",
    "df['Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['United States', 'Australia', 'Canada', 'Netherlands',\n",
       "       'United Kingdom', 'Poland', 'Japan', 'New Zealand', 'Italy',\n",
       "       'Vietnam', 'Republic of Ireland', 'Finland', 'Croatia', 'Israel',\n",
       "       'Germany', 'The Bahamas', 'Brazil', 'Russia', 'Norway',\n",
       "       'Indonesia', 'South Africa', 'Pakistan', 'India',\n",
       "       'Republic of Serbia', 'Argentina', 'Singapore', 'Sweden',\n",
       "       'Colombia', 'Mexico', 'Gibraltar', 'Venezuela'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the name in the Country column for USA to match GIS data name for USA\n",
    "df['Country'] = df['Country'].replace('United States of America','United States')\n",
    "df['Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "# How many countries is that?\n",
    "# Use the built-in len method to find the length of the array of unique country names.\n",
    "print(len(df['Country'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating the posts to get a weight for each country\n",
    "We would like to visualize how many posts are appearing in each country each year.  This means we need to get a frequency count by country for each year.\n",
    "We'll use Pandas (although this can also be done with arcpy by calling TabletoTable to make a DBF table and then calling the Frequency tool.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get a frequency table with Pandas\n",
    "\n",
    "The dataframe method named value_counts can be used to get the frequency of the posts in a country each year.  This returns a pandas series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <th>United States</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <th>United States</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <th>United States</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <th>United States</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2017</th>\n",
       "      <th>Australia</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russia</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Africa</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2018</th>\n",
       "      <th>Australia</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Croatia</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <th>United States</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "Year Country          \n",
       "2017 United States  45\n",
       "2014 United States  43\n",
       "2018 United States  38\n",
       "2016 United States  36\n",
       "2017 Australia      33\n",
       "...                 ..\n",
       "     Russia          1\n",
       "     South Africa    1\n",
       "2018 Australia       1\n",
       "     Croatia         1\n",
       "2022 United States   1\n",
       "\n",
       "[75 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_series = df.value_counts([\"Year\", \"Country\"])\n",
    "freq_df = freq_series.to_frame()\n",
    "freq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the dimensions in the above output?  This makes each year + country pairings the index for each row (the unique identifier field).   And the frequncy value is the **one column** .  The following code lists the index values (year-country tuples):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2017, 'United States') (2014, 'United States') (2018, 'United States')\n",
      " (2016, 'United States') (2017, 'Australia') (2015, 'United States')\n",
      " (2016, 'Australia') (2019, 'United States') (2018, 'Canada')\n",
      " (2015, 'Canada') (2019, 'Canada') (2020, 'United States')\n",
      " (2016, 'United Kingdom') (2020, 'Canada') (2021, 'Canada')\n",
      " (2016, 'Canada') (2021, 'United States') (2017, 'United Kingdom')\n",
      " (2016, 'India') (2014, 'United Kingdom') (2017, 'Canada')\n",
      " (2015, 'United Kingdom') (2014, 'Canada') (2019, 'Japan') (2015, 'Italy')\n",
      " (2020, 'Australia') (2015, 'Sweden') (2018, 'United Kingdom')\n",
      " (2013, 'United States') (2019, 'United Kingdom') (2014, 'Colombia')\n",
      " (2019, 'Italy') (2019, 'Australia') (2019, 'Finland')\n",
      " (2018, 'The Bahamas') (2013, 'Australia') (2019, 'Republic of Ireland')\n",
      " (2019, 'Vietnam') (2018, 'Japan') (2020, 'Japan') (2020, 'New Zealand')\n",
      " (2020, 'Poland') (2020, 'United Kingdom') (2021, 'Australia')\n",
      " (2021, 'Netherlands') (2021, 'United Kingdom')\n",
      " (2018, 'Republic of Ireland') (2017, 'Norway') (2018, 'Israel')\n",
      " (2016, 'New Zealand') (2014, 'Gibraltar') (2014, 'India')\n",
      " (2014, 'Mexico') (2014, 'Sweden') (2014, 'Venezuela') (2015, 'Australia')\n",
      " (2016, 'Argentina') (2016, 'Croatia') (2016, 'Finland') (2016, 'Germany')\n",
      " (2016, 'Italy') (2016, 'Republic of Ireland') (2018, 'Germany')\n",
      " (2016, 'Republic of Serbia') (2016, 'Singapore') (2016, 'South Africa')\n",
      " (2017, 'Brazil') (2017, 'Indonesia') (2017, 'Israel') (2017, 'Pakistan')\n",
      " (2017, 'Russia') (2017, 'South Africa') (2018, 'Australia')\n",
      " (2018, 'Croatia') (2022, 'United States')]\n",
      "RangeIndex(start=0, stop=1, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(freq_df.index.values)\n",
    "print(freq_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following this approach described on [stackoverflow]{https://stackoverflow.com/questions/47136436/python-pandas-convert-value-counts-output-to-dataframe}, we'll reset the index.  This generates a new unique ID (index) for each row.   Then we can rename the columns, to name our new column \"Frequency\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df_reset = freq_df.reset_index()\n",
    "freq_df_reset\n",
    "# Rename the last column to \"Frequency\"\n",
    "freq_df_reset.columns = [\"Year\", \"Country\",\"Frequency\"]\n",
    "## Add code to print the head of freq_df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Get the overall maximum and minimum frequencies for later use.\n",
    "max_country_count = freq_df_reset['Frequency'].max()\n",
    "min_country_count = freq_df_reset['Frequency'].min()\n",
    "print(max_country_count)\n",
    "print(min_country_count)\n",
    "\n",
    "## Add code to print the maximum and minimum year in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a copy of the worldwide countries dataset\n",
    "\n",
    "Other data will be joined to this, so we want to preserve the original before modifying the table.\n",
    "\n",
    "Data source: \n",
    "[ArcGIS Hub World Countries Generalized] (https://hub.arcgis.com/datasets/2b93b06dc0dc4e809d3c8db5cb96ba69_0/explore?location=-0.101905%2C0.000000%2C2.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, April 27, 2023 11:54:53 PM\",\"Succeeded at Thursday, April 27, 2023 11:54:53 PM (Elapsed Time: 0.47 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\echoi4\\\\Desktop\\\\esterArcGISProject-20230428T013544Z-001\\\\esterArcGISProject\\\\outputFreq\\\\worldEstherFreq.shp'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arcpy\n",
    "arcpy.env.workspace = projectDir + r'esterArcGISProject.gdb'\n",
    "arcpy.env.overwriteOutput = True\n",
    "worldData = 'world_countries'\n",
    "worldDataCopy = workingDir + 'worldEstherFreq.shp'\n",
    "arcpy.CopyFeatures_management(worldData, worldDataCopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'essie'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a the base name (without the extention) of the input data.  We'll use this to name files in the next part.\n",
    "baseName = os.path.basename(myData)\n",
    "baseName = os.path.splitext(baseName)[0]\n",
    "baseName = baseName.split(\"_\")[0]\n",
    "baseName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a table for each time step and join the tables with the GIS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in 2013: 3\n",
      "Year:   2013\n",
      "['United States' 'Australia']\n",
      "Field names before: ['OBJECTID', 'Shape', 'worldEstherFreq_FID_1', 'worldEstherFreq_COUNTRY', 'worldEstherFreq_ISO', 'worldEstherFreq_COUNTRYAFF', 'worldEstherFreq_AFF_ISO', 'worldEstherFreq_SHAPE_Leng', 'worldEstherFreq_Shape_Le_1', 'essie2013_csv_Field1', 'essie2013_csv_Year', 'essie2013_csv_Country', 'essie2013_csv_Frequency', 'Shape_Length', 'Shape_Area']\n",
      "Field names after: ['OBJECTID', 'Shape', 'worldEstherFreq_FID_1', 'worldEstherFreq_COUNTRY', 'worldEstherFreq_ISO', 'worldEstherFreq_COUNTRYAFF', 'worldEstherFreq_AFF_ISO', 'worldEstherFreq_SHAPE_Leng', 'worldEstherFreq_Shape_Le_1', 'essie2013_csv_Field1', 'essie2013_csv_Year', 'essie2013_csv_Country', 'Count', 'Shape_Length', 'Shape_Area']\n",
      "Number of records in 2014: 60\n",
      "Year:   2014\n",
      "['United States' 'United Kingdom' 'Canada' 'Colombia' 'Gibraltar' 'India'\n",
      " 'Mexico' 'Sweden' 'Venezuela']\n",
      "Field names before: ['OBJECTID', 'Shape', 'worldEstherFreq_FID_1', 'worldEstherFreq_COUNTRY', 'worldEstherFreq_ISO', 'worldEstherFreq_COUNTRYAFF', 'worldEstherFreq_AFF_ISO', 'worldEstherFreq_SHAPE_Leng', 'worldEstherFreq_Shape_Le_1', 'essie2014_csv_Field1', 'essie2014_csv_Year', 'essie2014_csv_Country', 'essie2014_csv_Frequency', 'Shape_Length', 'Shape_Area']\n",
      "Field names after: ['OBJECTID', 'Shape', 'worldEstherFreq_FID_1', 'worldEstherFreq_COUNTRY', 'worldEstherFreq_ISO', 'worldEstherFreq_COUNTRYAFF', 'worldEstherFreq_AFF_ISO', 'worldEstherFreq_SHAPE_Leng', 'worldEstherFreq_Shape_Le_1', 'essie2014_csv_Field1', 'essie2014_csv_Year', 'essie2014_csv_Country', 'Count', 'Shape_Length', 'Shape_Area']\n",
      "Number of records in 2015: 62\n",
      "Year:   2015\n",
      "['United States' 'Canada' 'United Kingdom' 'Italy' 'Sweden' 'Australia']\n",
      "Field names before: ['OBJECTID', 'Shape', 'worldEstherFreq_FID_1', 'worldEstherFreq_COUNTRY', 'worldEstherFreq_ISO', 'worldEstherFreq_COUNTRYAFF', 'worldEstherFreq_AFF_ISO', 'worldEstherFreq_SHAPE_Leng', 'worldEstherFreq_Shape_Le_1', 'essie2015_csv_Field1', 'essie2015_csv_Year', 'essie2015_csv_Country', 'essie2015_csv_Frequency', 'Shape_Length', 'Shape_Area']\n",
      "Field names after: ['OBJECTID', 'Shape', 'worldEstherFreq_FID_1', 'worldEstherFreq_COUNTRY', 'worldEstherFreq_ISO', 'worldEstherFreq_COUNTRYAFF', 'worldEstherFreq_AFF_ISO', 'worldEstherFreq_SHAPE_Leng', 'worldEstherFreq_Shape_Le_1', 'essie2015_csv_Field1', 'essie2015_csv_Year', 'essie2015_csv_Country', 'Count', 'Shape_Length', 'Shape_Area']\n",
      "Number of records in 2016: 100\n",
      "Year:   2016\n",
      "['United States' 'Australia' 'United Kingdom' 'Canada' 'India'\n",
      " 'New Zealand' 'Argentina' 'Croatia' 'Finland' 'Germany' 'Italy'\n",
      " 'Republic of Ireland' 'Republic of Serbia' 'Singapore' 'South Africa']\n",
      "Field names before: ['OBJECTID', 'Shape', 'worldEstherFreq_FID_1', 'worldEstherFreq_COUNTRY', 'worldEstherFreq_ISO', 'worldEstherFreq_COUNTRYAFF', 'worldEstherFreq_AFF_ISO', 'worldEstherFreq_SHAPE_Leng', 'worldEstherFreq_Shape_Le_1', 'essie2016_csv_Field1', 'essie2016_csv_Year', 'essie2016_csv_Country', 'essie2016_csv_Frequency', 'Shape_Length', 'Shape_Area']\n",
      "Field names after: ['OBJECTID', 'Shape', 'worldEstherFreq_FID_1', 'worldEstherFreq_COUNTRY', 'worldEstherFreq_ISO', 'worldEstherFreq_COUNTRYAFF', 'worldEstherFreq_AFF_ISO', 'worldEstherFreq_SHAPE_Leng', 'worldEstherFreq_Shape_Le_1', 'essie2016_csv_Field1', 'essie2016_csv_Year', 'essie2016_csv_Country', 'Count', 'Shape_Length', 'Shape_Area']\n",
      "Number of records in 2017: 98\n",
      "Year:   2017\n",
      "['United States' 'Australia' 'United Kingdom' 'Canada' 'Norway' 'Brazil'\n",
      " 'Indonesia' 'Israel' 'Pakistan' 'Russia' 'South Africa']\n",
      "Field names before: ['OBJECTID', 'Shape', 'worldEstherFreq_FID_1', 'worldEstherFreq_COUNTRY', 'worldEstherFreq_ISO', 'worldEstherFreq_COUNTRYAFF', 'worldEstherFreq_AFF_ISO', 'worldEstherFreq_SHAPE_Leng', 'worldEstherFreq_Shape_Le_1', 'essie2017_csv_Field1', 'essie2017_csv_Year', 'essie2017_csv_Country', 'essie2017_csv_Frequency', 'Shape_Length', 'Shape_Area']\n",
      "Field names after: ['OBJECTID', 'Shape', 'worldEstherFreq_FID_1', 'worldEstherFreq_COUNTRY', 'worldEstherFreq_ISO', 'worldEstherFreq_COUNTRYAFF', 'worldEstherFreq_AFF_ISO', 'worldEstherFreq_SHAPE_Leng', 'worldEstherFreq_Shape_Le_1', 'essie2017_csv_Field1', 'essie2017_csv_Year', 'essie2017_csv_Country', 'Count', 'Shape_Length', 'Shape_Area']\n",
      "Number of records in 2018: 68\n",
      "Year:   2018\n",
      "['United States' 'Canada' 'United Kingdom' 'The Bahamas' 'Japan'\n",
      " 'Republic of Ireland' 'Israel' 'Germany' 'Australia' 'Croatia']\n",
      "Field names before: ['OBJECTID', 'Shape', 'worldEstherFreq_FID_1', 'worldEstherFreq_COUNTRY', 'worldEstherFreq_ISO', 'worldEstherFreq_COUNTRYAFF', 'worldEstherFreq_AFF_ISO', 'worldEstherFreq_SHAPE_Leng', 'worldEstherFreq_Shape_Le_1', 'essie2018_csv_Field1', 'essie2018_csv_Year', 'essie2018_csv_Country', 'essie2018_csv_Frequency', 'Shape_Length', 'Shape_Area']\n",
      "Field names after: ['OBJECTID', 'Shape', 'worldEstherFreq_FID_1', 'worldEstherFreq_COUNTRY', 'worldEstherFreq_ISO', 'worldEstherFreq_COUNTRYAFF', 'worldEstherFreq_AFF_ISO', 'worldEstherFreq_SHAPE_Leng', 'worldEstherFreq_Shape_Le_1', 'essie2018_csv_Field1', 'essie2018_csv_Year', 'essie2018_csv_Country', 'Count', 'Shape_Length', 'Shape_Area']\n",
      "Number of records in 2019: 52\n",
      "Year:   2019\n",
      "['United States' 'Canada' 'Japan' 'United Kingdom' 'Italy' 'Australia'\n",
      " 'Finland' 'Republic of Ireland' 'Vietnam']\n",
      "Field names before: ['OBJECTID', 'Shape', 'worldEstherFreq_FID_1', 'worldEstherFreq_COUNTRY', 'worldEstherFreq_ISO', 'worldEstherFreq_COUNTRYAFF', 'worldEstherFreq_AFF_ISO', 'worldEstherFreq_SHAPE_Leng', 'worldEstherFreq_Shape_Le_1', 'essie2019_csv_Field1', 'essie2019_csv_Year', 'essie2019_csv_Country', 'essie2019_csv_Frequency', 'Shape_Length', 'Shape_Area']\n",
      "Field names after: ['OBJECTID', 'Shape', 'worldEstherFreq_FID_1', 'worldEstherFreq_COUNTRY', 'worldEstherFreq_ISO', 'worldEstherFreq_COUNTRYAFF', 'worldEstherFreq_AFF_ISO', 'worldEstherFreq_SHAPE_Leng', 'worldEstherFreq_Shape_Le_1', 'essie2019_csv_Field1', 'essie2019_csv_Year', 'essie2019_csv_Country', 'Count', 'Shape_Length', 'Shape_Area']\n",
      "Number of records in 2020: 28\n",
      "Year:   2020\n",
      "['United States' 'Canada' 'Australia' 'Japan' 'New Zealand' 'Poland'\n",
      " 'United Kingdom']\n",
      "Field names before: ['OBJECTID', 'Shape', 'worldEstherFreq_FID_1', 'worldEstherFreq_COUNTRY', 'worldEstherFreq_ISO', 'worldEstherFreq_COUNTRYAFF', 'worldEstherFreq_AFF_ISO', 'worldEstherFreq_SHAPE_Leng', 'worldEstherFreq_Shape_Le_1', 'essie2020_csv_Field1', 'essie2020_csv_Year', 'essie2020_csv_Country', 'essie2020_csv_Frequency', 'Shape_Length', 'Shape_Area']\n",
      "Field names after: ['OBJECTID', 'Shape', 'worldEstherFreq_FID_1', 'worldEstherFreq_COUNTRY', 'worldEstherFreq_ISO', 'worldEstherFreq_COUNTRYAFF', 'worldEstherFreq_AFF_ISO', 'worldEstherFreq_SHAPE_Leng', 'worldEstherFreq_Shape_Le_1', 'essie2020_csv_Field1', 'essie2020_csv_Year', 'essie2020_csv_Country', 'Count', 'Shape_Length', 'Shape_Area']\n",
      "Number of records in 2021: 18\n",
      "Year:   2021\n",
      "['Canada' 'United States' 'Australia' 'Netherlands' 'United Kingdom']\n",
      "Field names before: ['OBJECTID', 'Shape', 'worldEstherFreq_FID_1', 'worldEstherFreq_COUNTRY', 'worldEstherFreq_ISO', 'worldEstherFreq_COUNTRYAFF', 'worldEstherFreq_AFF_ISO', 'worldEstherFreq_SHAPE_Leng', 'worldEstherFreq_Shape_Le_1', 'essie2021_csv_Field1', 'essie2021_csv_Year', 'essie2021_csv_Country', 'essie2021_csv_Frequency', 'Shape_Length', 'Shape_Area']\n",
      "Field names after: ['OBJECTID', 'Shape', 'worldEstherFreq_FID_1', 'worldEstherFreq_COUNTRY', 'worldEstherFreq_ISO', 'worldEstherFreq_COUNTRYAFF', 'worldEstherFreq_AFF_ISO', 'worldEstherFreq_SHAPE_Leng', 'worldEstherFreq_Shape_Le_1', 'essie2021_csv_Field1', 'essie2021_csv_Year', 'essie2021_csv_Country', 'Count', 'Shape_Length', 'Shape_Area']\n",
      "Number of records in 2022: 1\n",
      "Year:   2022\n",
      "['United States']\n",
      "Field names before: ['OBJECTID', 'Shape', 'worldEstherFreq_FID_1', 'worldEstherFreq_COUNTRY', 'worldEstherFreq_ISO', 'worldEstherFreq_COUNTRYAFF', 'worldEstherFreq_AFF_ISO', 'worldEstherFreq_SHAPE_Leng', 'worldEstherFreq_Shape_Le_1', 'essie2022_csv_Field1', 'essie2022_csv_Year', 'essie2022_csv_Country', 'essie2022_csv_Frequency', 'Shape_Length', 'Shape_Area']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field names after: ['OBJECTID', 'Shape', 'worldEstherFreq_FID_1', 'worldEstherFreq_COUNTRY', 'worldEstherFreq_ISO', 'worldEstherFreq_COUNTRYAFF', 'worldEstherFreq_AFF_ISO', 'worldEstherFreq_SHAPE_Leng', 'worldEstherFreq_Shape_Le_1', 'essie2022_csv_Field1', 'essie2022_csv_Year', 'essie2022_csv_Country', 'Count', 'Shape_Length', 'Shape_Area']\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "# Create an empty dictionary to store the number of records per year.\n",
    "yearly_count = {}\n",
    "max_country_count = freq_df_reset['Frequency'].max()\n",
    "min_country_count = freq_df_reset['Frequency'].min()\n",
    "# For each year in the reduced dataset, create a csv file.\n",
    "\n",
    "for yr in sorted(freq_df_reset['Year'].unique()):\n",
    "    # Select rows based on the year\n",
    "    rslt_df = freq_df_reset[freq_df_reset['Year'] == yr]\n",
    "    recordsThisYear = rslt_df['Frequency'].sum() \n",
    "    print(f\"Number of records in {yr}: {recordsThisYear}\" ) \n",
    "    yearly_count[yr] = len(rslt_df)\n",
    "\n",
    "    # Prepare an output name\n",
    "    annualCSV = workingDir + f'{baseName}{yr}.csv'\n",
    "    \n",
    "    # Write the data frame to csv\n",
    "    rslt_df.to_csv(annualCSV)\n",
    "    \n",
    "    print(f'Year:   {yr}')\n",
    "    print(rslt_df['Country'].unique())\n",
    "    \n",
    "    # Join the data\n",
    "    joinedData = arcpy.management.AddJoin(\n",
    "        in_layer_or_view = worldDataCopy, \n",
    "        in_field = 'COUNTRY', \n",
    "        join_table = annualCSV, \n",
    "        join_field = 'Country', \n",
    "    join_type = 'KEEP_COMMON')\n",
    "    \n",
    "    curData = fileGDB + f'{baseName}{yr}'\n",
    "    try:\n",
    "        # The frequency field automatic name is quite long.  E.g., esther_reduced2013_csv_Frequency\n",
    "        # Let's rename it.\n",
    "        \n",
    "        cur_frequency_field = f'{os.path.basename(annualCSV).replace(\".\",\"_\")}_Frequency'\n",
    "        frequency_field = 'Count'\n",
    "        arcpy.CopyFeatures_management(joinedData, curData)\n",
    "        fds = arcpy.ListFields(curData)\n",
    "        print(f\"Field names before: {[f.name for f in fds]}\")\n",
    "        arcpy.management.AlterField(curData, cur_frequency_field, frequency_field, frequency_field)\n",
    "        fds = arcpy.ListFields(curData)\n",
    "        print(f\"Field names after: {[f.name for f in fds]}\")\n",
    "        shpData = workingDir + f'{baseName}{yr}.shp'\n",
    "        arcpy.management.CopyFeatures(curData, shpData)\n",
    "        \n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        print(\"File already exists.  New copy not created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add records so that graduated colors will be normalized\n",
    "\n",
    "If we use graduated colors for the count on a year that has min 1 and max 5, the 5 will be colored the same as the max in another year that has max of 100.  As a way of normalizing the data for the purposes of visualizing it, we'll add a two new dummy records to each dataset. One new record will have the maximum value of all the years in the Count column.  The other will have the overall minimum in the Count column. The records will be dummies in the sense that they won't have any geometry, so they won't be displayed on the map, but they will still normalize the graduated colors so that the color steps are consistant across the years.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for yr in sorted(freq_df_reset['Year'].unique()):\n",
    "    try:\n",
    "        curData = fileGDB + f'{baseName}{yr}'\n",
    "        with arcpy.da.InsertCursor(curData, [frequency_field]) as ic:\n",
    "            newRecord = [max_country_count]\n",
    "            ic.insertRow(newRecord)\n",
    "            newRecord = [min_country_count]\n",
    "            ic.insertRow(newRecord)\n",
    "        del ic\n",
    "    except:\n",
    "        print(arcpy.GetMessages() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Color ramps\n",
    "We're going to use graduated color for our frequency counts.  You can specify color ramps by name.  \n",
    "See a complete list of color ramps by uncommenting the following code (remove the hash tags at the beginning of each line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "C:\\Users\\echoi4\\Desktop\\esterArcGISProject-20230428T013544Z-001\\esterArcGISProjectestherArcGISProject.aprx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "In  \u001b[0;34m[49]\u001b[0m:\nLine \u001b[0;34m1\u001b[0m:     aprx = arcpy.mp.ArcGISProject(projectDir + \u001b[33m'\u001b[39;49;00m\u001b[33mestherArcGISProject.aprx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\_mp.py\u001b[0m, in \u001b[0;32m__init__\u001b[0m:\nLine \u001b[0;34m536\u001b[0m:   \u001b[36mself\u001b[39;49;00m._arc_object = arcgisscripting._mapping.ArcGISProject(*gp_fixargs((aprx_path,), \u001b[34mTrue\u001b[39;49;00m))\n",
      "\u001b[0;31mOSError\u001b[0m: C:\\Users\\echoi4\\Desktop\\esterArcGISProject-20230428T013544Z-001\\esterArcGISProjectestherArcGISProject.aprx\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "#aprx = arcpy.mp.ArcGISProject(projectDir + 'estherArcGISProject.aprx')\n",
    "#ramps = aprx.listColorRamps()\n",
    "#for ramp in ramps:\n",
    "    print (ramp.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worldwide Countries\n",
      "Human Geography Dark Label\n",
      "Human Geography Dark Detail\n",
      "Human Geography Dark Base\n"
     ]
    }
   ],
   "source": [
    "# aprx is the ArcGIS project object\n",
    "\n",
    "# Get a list of maps in this project.\n",
    "myMap = aprx.listMaps('Map')[0]\n",
    "layers = myMap.listLayers()\n",
    "layer_object = layers[0]\n",
    "count = 0 \n",
    "while \"Worldwide\" not in layer_object.name and count < len(layers):\n",
    "    print(layer_object.name)\n",
    "    myMap.removeLayer(layer_object)\n",
    "    count = count + 1\n",
    "    layer_object = layers[count]\n",
    "    \n",
    "for layer in layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create map layers and take screenshots\n",
    "\n",
    "We'll do this by looping through the years. Earlier, we created a shapefile for each year.  Now we'll make a layer for each shapefile.   We'll add it to the map, capture a screenshot (a png image), and turn then that layer's visibility off, so that we can do the same again with the next shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layout elements on Layout_w_surrounds:\n",
      "\tLegend\n",
      "\tText\n",
      "\tNorth Arrow\n",
      "\tMap Frame\n",
      "Creating the essie2013 layer.\n",
      "Creating the essie2014 layer.\n",
      "Creating the essie2015 layer.\n",
      "Creating the essie2016 layer.\n",
      "Creating the essie2017 layer.\n",
      "Creating the essie2018 layer.\n",
      "Creating the essie2019 layer.\n",
      "Creating the essie2020 layer.\n",
      "Creating the essie2021 layer.\n",
      "Creating the essie2022 layer.\n"
     ]
    }
   ],
   "source": [
    "# Get a list of maps in this project.\n",
    "myMap = aprx.listMaps('Map')[0]\n",
    "\n",
    "custom_layout = aprx.listLayouts(\"*surround*\")[0]\n",
    "print(f\"Layout elements on {custom_layout.name}:\")\n",
    "for elem in custom_layout.listElements():\n",
    "    print(\"\\t\" + elem.name)\n",
    "    if \"Text\" in elem.name:\n",
    "        textbox = elem\n",
    "\n",
    "\n",
    "RGBs = [[190, 210, 255, 60], [245, 122, 122, 60], [255, 255, 0, 60]]\n",
    "\n",
    "# For each year in the data, add a layer and export an image of it.\n",
    "for yr in sorted(freq_df_reset['Year'].unique()):\n",
    "\n",
    "    # Get the name of the shapefile associated with the current year. \n",
    "    curData = workingDir + f'{baseName}{yr}.shp'\n",
    "    \n",
    "    # Add the shapefile as a layer on the map.\n",
    "    myMap.addDataFromPath(curData)\n",
    "    # Set the text string to current year\n",
    "    textbox.text = yr\n",
    "    \n",
    "    # Now we need the layer object associated with our new layer. \n",
    "    # This gives access to the symbology properties of the layer.  \n",
    "    # Get a list of layor objects for the layers on this map.\n",
    "    layerObjects = myMap.listLayers()\n",
    "    \n",
    "    # Get the first one (the most recently added to the map)\n",
    "    lay = layerObjects[0]\n",
    "\n",
    "    print(f'Creating the {lay.name} layer.')\n",
    "    \n",
    "    sym = lay.symbology\n",
    "\n",
    "    if lay.isFeatureLayer and hasattr(sym, \"renderer\"):\n",
    "    \n",
    "        # Modify the symbology object.\n",
    "        sym.updateRenderer(\"GraduatedColorsRenderer\")\n",
    "        sym.renderer.classificationField = frequency_field\n",
    "        sym.renderer.classificationMethod = \"EqualInterval\"\n",
    "        ## Modify the number of breaks and the color ramp (see the code box before this for choices).\n",
    "        sym.renderer.breakCount = 5\n",
    "        sym.renderer.colorRamp = aprx.listColorRamps(\"Yellow-Orange-Red (5 Classes)\")[0]\n",
    "\n",
    "        # Set the layer's symbology to the updated symbology object.\n",
    "        lay.symbology = sym \n",
    "\n",
    "    lay.symbology = sym\n",
    "   \n",
    "    # Capture a screen shot of the newly added and symbolized layer.\n",
    "    outPic = visDir+f'{baseName}{str(yr).zfill(2)}.png'\n",
    "    custom_layout.exportToPNG(outPic)\n",
    "    # Turn the layer off to prepare for the adding the next one and capturing an image.\n",
    "    lay.visible = False\n",
    "    \n",
    "    del lay\n",
    "\n",
    "# Capture an image of the legend.\n",
    "# Turn on one of the layers so that the legend will show the patches\n",
    "lay = layerObjects[0]\n",
    "\n",
    "\n",
    "lay.visible = True\n",
    "\n",
    "# The project has a layout specifically designed to display only the legend.\n",
    "# Here we're getting the layout object associated with it.  \n",
    "# This layout view has the word 'legend' in it.\n",
    "custom_layout = aprx.listLayouts(\"*legend*\")[0]\n",
    "\n",
    "# Enlarge the legend patches.  The default is too small for our purposes.\n",
    "leg = custom_layout.listElements('LEGEND_ELEMENT')[0]\n",
    "\n",
    "for itm in leg.items:\n",
    "    # Specify the size in pts\n",
    "    itm.patchHeight = 50\n",
    "    itm.patchWidth = 100\n",
    "\n",
    "legendName = visDir + f'legend.png'\n",
    "custom_layout.exportToPNG(legendName)\n",
    "    \n",
    "del myMap\n",
    "del aprx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curData\n",
    "x = \"C:/gispy/esterArcGISProject/esterArcGISProject.gdb/essie2013\"\n",
    "#myMap.addDataFromPath(x)\n",
    "arcpy.Exists(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more graduated color arcpy examples, see this 'how to' page: [https://support.esri.com/en/technical-article/000020468]\n",
    "\n",
    "For more information about legend items, see this ESRI help page: [https://pro.arcgis.com/en/pro-app/2.8/arcpy/mapping/legenditem-class.htm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creat an animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[53]:12: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\echoi4\\Desktop\\esterArcGISProject-20230428T013544Z-001\\esterArcGISProject\\outputFreq\\\\picsFreq\\/movie.gif created using 10 maps!\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "images = []\n",
    "import os\n",
    "mapPics = os.listdir(visDir)\n",
    "\n",
    "movieName = visDir + '/movie.gif'\n",
    "if os.path.exists(movieName):\n",
    "    os.remove(movieName)\n",
    "\n",
    "for pic in mapPics:\n",
    "    if pic.endswith(\"png\") and \"legend\" not in pic:\n",
    "        images.append(imageio.imread(visDir + pic))\n",
    "\n",
    "\n",
    "imageio.mimsave(movieName, images, duration=0.8)\n",
    "image_count = len(images)\n",
    "print('{} created using {} maps!'.format( movieName, image_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['essie2013.png', 'essie2014.png', 'essie2015.png', 'essie2016.png', 'essie2017.png', 'essie2018.png', 'essie2019.png', 'essie2020.png', 'essie2021.png', 'essie2022.png', 'legend.png']\n"
     ]
    }
   ],
   "source": [
    "# Check file names.\n",
    "print(mapPics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an html display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = \"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "div.gallery {\n",
    "  border: 1px solid #ccc;\n",
    "}\n",
    "\n",
    "div.gallery:hover {\n",
    "  border: 1px solid #777;\n",
    "}\n",
    "\n",
    "div.gallery img {\n",
    "  width: 100%;\n",
    "  height: auto;\n",
    "}\n",
    "\n",
    "div.desc {\n",
    "  padding: 15px;\n",
    "  text-align: center;\n",
    "}\n",
    "\n",
    "* {\n",
    "  box-sizing: border-box;\n",
    "}\n",
    "\n",
    ".responsive {\n",
    "  padding: 0 6px;\n",
    "  float: left;\n",
    "  width: 24.99999%;\n",
    "}\n",
    "\n",
    "@media only screen and (max-width: 700px) {\n",
    "  .responsive {\n",
    "    width: 49.99999%;\n",
    "    margin: 6px 0;\n",
    "  }\n",
    "}\n",
    "\n",
    "@media only screen and (max-width: 500px) {\n",
    "  .responsive {\n",
    "    width: 100%;\n",
    "  }\n",
    "}\n",
    "\n",
    ".clearfix:after {\n",
    "  content: \"\";\n",
    "  display: table;\n",
    "  clear: both;\n",
    "}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\"\"\" \n",
    "\n",
    "bodyContent = f\"\"\"<h2>{baseName.title()} Posts Over {image_count} Years </h2>\n",
    "<h4>Author: Jane Doe</h4>\n",
    "<h4>Data source: {baseName} social media posts</h4>\"\"\"\n",
    "\n",
    "mapPics = os.listdir(visDir)\n",
    "\n",
    "mapPics = [picName for picName in mapPics if picName.endswith('.png') and \"legend\" not in picName ]\n",
    "\n",
    "for pic in mapPics:\n",
    "    dateVal = os.path.splitext(pic)[0]\n",
    "    dateVal = dateVal.replace(baseName,'')\n",
    "    dateVal = int(dateVal)\n",
    "\n",
    "    bodyContent = bodyContent + f\"\"\"<div class=\"responsive\"><div class=\"gallery\">\n",
    "  <a target=\"_blank\" href={pic}>\n",
    "    <img src={pic} alt=\"{os.path.splitext(pic)[0]}\" width=\"800\" height=\"600\">\n",
    "  </a>\n",
    "  <div class=\"desc\">{yearly_count[dateVal]} {baseName.title()} post(s) in {dateVal}</div>\n",
    "</div></div>\"\"\"\n",
    "\n",
    "# Add legend\n",
    "legendName = os.path.basename(legendName)\n",
    "bodyContent = bodyContent + f\"\"\"<div class=\"responsive\"><div class=\"gallery\">\n",
    "  <a target=\"_blank\" href={legendName}>\n",
    "    <img src={legendName} alt=\"animation\" width=\"800\" height=\"600\">\n",
    "  </a>\n",
    "  <div class=\"desc\">{baseName.title()} post count ranges</div>\n",
    "</div></div>\"\"\"\n",
    "\n",
    "# Add movie\n",
    "movieName = os.path.basename(movieName)\n",
    "bodyContent = bodyContent + f\"\"\"<div class=\"responsive\"><div class=\"gallery\">\n",
    "  <a target=\"_blank\" href={movieName}>\n",
    "    <img src={movieName} alt=\"animation\" width=\"800\" height=\"600\">\n",
    "  </a>\n",
    "  <div class=\"desc\">{baseName.title()} posts over time.</div>\n",
    "</div></div>\"\"\"\n",
    "\n",
    "\n",
    "footer = \"\"\"</body>\n",
    "</html>\"\"\"\n",
    "\n",
    "html_file_name = visDir + f'{baseName}.html'\n",
    "\n",
    "with open( html_file_name,'w') as outFileObject:\n",
    "  outFileObject.write(header)\n",
    "  outFileObject.write(bodyContent)\n",
    "  outFileObject.write(footer)\n",
    "os.startfile(html_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0515d880074d3a778d90148b56f6d3aa63d459907926b681bcdb25236e1288ae"
  },
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
