{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query Id</th>\n",
       "      <th>Query Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Url</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Page Type</th>\n",
       "      <th>Language</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Continent Code</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Country</th>\n",
       "      <th>City Code</th>\n",
       "      <th>Account Type</th>\n",
       "      <th>Added</th>\n",
       "      <th>Assignment</th>\n",
       "      <th>Author</th>\n",
       "      <th>Avatar</th>\n",
       "      <th>Category Details</th>\n",
       "      <th>Checked</th>\n",
       "      <th>City</th>\n",
       "      <th>Display URLs</th>\n",
       "      <th>Expanded URLs</th>\n",
       "      <th>Facebook Author ID</th>\n",
       "      <th>Facebook Comments</th>\n",
       "      <th>Facebook Likes</th>\n",
       "      <th>Facebook Role</th>\n",
       "      <th>Facebook Shares</th>\n",
       "      <th>Facebook Subtype</th>\n",
       "      <th>Full Name</th>\n",
       "      <th>Full Text</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Impact</th>\n",
       "      <th>Impressions</th>\n",
       "      <th>Instagram Comments</th>\n",
       "      <th>Instagram Followers</th>\n",
       "      <th>Instagram Following</th>\n",
       "      <th>Instagram Interactions Count</th>\n",
       "      <th>...</th>\n",
       "      <th>Twitter Channel Role</th>\n",
       "      <th>Twitter Followers</th>\n",
       "      <th>Twitter Following</th>\n",
       "      <th>Twitter Reply Count</th>\n",
       "      <th>Twitter Reply to</th>\n",
       "      <th>Twitter Retweet of</th>\n",
       "      <th>Twitter Retweets</th>\n",
       "      <th>Twitter Tweets</th>\n",
       "      <th>Twitter Verified</th>\n",
       "      <th>Updated</th>\n",
       "      <th>Reach (new)</th>\n",
       "      <th>Blog Name</th>\n",
       "      <th>Copyright</th>\n",
       "      <th>Engagement Type</th>\n",
       "      <th>Entity Info</th>\n",
       "      <th>Item Review</th>\n",
       "      <th>Linkedin Comments</th>\n",
       "      <th>Linkedin Engagement</th>\n",
       "      <th>Linkedin Impressions</th>\n",
       "      <th>Linkedin Likes</th>\n",
       "      <th>Linkedin Shares</th>\n",
       "      <th>Linkedin Sponsored</th>\n",
       "      <th>Linkedin Video Views</th>\n",
       "      <th>Page Type Name</th>\n",
       "      <th>Parent Blog Name</th>\n",
       "      <th>Parent Post Id</th>\n",
       "      <th>Pub Type</th>\n",
       "      <th>Publisher Sub Type</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reddit Author Awardee Karma</th>\n",
       "      <th>Reddit Author Awarder Karma</th>\n",
       "      <th>Reddit Author Karma</th>\n",
       "      <th>Reddit Score</th>\n",
       "      <th>Region</th>\n",
       "      <th>Region Code</th>\n",
       "      <th>Root Blog Name</th>\n",
       "      <th>Root Post Id</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Subreddit Subscribers</th>\n",
       "      <th>Weblog Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000705381</td>\n",
       "      <td>LT - SLF Twitter Penn since 2011</td>\n",
       "      <td>2022-01-26 22:20:25.0</td>\n",
       "      <td>‚ÄúIt‚Äôs a micro mini pig! It fits in a teacup!‚Äù ...</td>\n",
       "      <td>https://www.reddit.com/r/TeenMomOGandTeenMom2/...</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>neutral</td>\n",
       "      <td>reddit</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-02-14T17:53:04.954+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Midnight_Ravioli</td>\n",
       "      <td>https://styles.redditmedia.com/t5_zc3na/styles...</td>\n",
       "      <td>{id=11239953, name=Other, displayName=null, pa...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Midnight_Ravioli</td>\n",
       "      <td>Reminds me of Ester the wonder pig. My mom bou...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-14T17:53:04.954+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{entityId=13417213, entityConfidence=HIGH, url...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sda395</td>\n",
       "      <td>BW_REDDIT_REPLY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13666.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sda395</td>\n",
       "      <td>TeenMomOGandTeenMom2</td>\n",
       "      <td>108360</td>\n",
       "      <td>Midnight_Ravioli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000705381</td>\n",
       "      <td>LT - SLF Twitter Penn since 2011</td>\n",
       "      <td>2022-01-10 01:00:58.0</td>\n",
       "      <td>@mkramer For giggles, you can follow Ester the...</td>\n",
       "      <td>http://twitter.com/MarySwannParry/statuses/148...</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>neutral</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>USA</td>\n",
       "      <td>NORTH AMERICA</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>individual</td>\n",
       "      <td>2022-02-14T17:53:03.014+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MarySwannParry</td>\n",
       "      <td>https://audiences.brandwatch.com/api/audiences...</td>\n",
       "      <td>{id=11239953, name=Other, displayName=null, pa...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.instagram.com/estherthewonderpig/?...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MarySwannParry (Mary Swann Parry)</td>\n",
       "      <td>@mkramer For giggles, you can follow Ester the...</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1684</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1684</td>\n",
       "      <td>2712</td>\n",
       "      <td>0</td>\n",
       "      <td>http://twitter.com/mkramer/statuses/1480193116...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10978</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-14T17:53:03.014+0000</td>\n",
       "      <td>901.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REPLY</td>\n",
       "      <td>{entityId=209330, entityConfidence=HIGH, url=h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitstream</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MarySwannParry (Mary Swann Parry)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000705381</td>\n",
       "      <td>LT - SLF Twitter Penn since 2011</td>\n",
       "      <td>2021-11-20 17:45:39.0</td>\n",
       "      <td>@PixieZelda Ester the Wonder Pig would approve!</td>\n",
       "      <td>http://twitter.com/MiralukaFan/statuses/146211...</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>neutral</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>AUS</td>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>Australia/Oceania</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>individual</td>\n",
       "      <td>2022-02-14T17:53:05.447+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MiralukaFan</td>\n",
       "      <td>https://audiences.brandwatch.com/api/audiences...</td>\n",
       "      <td>{id=11239953, name=Other, displayName=null, pa...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MiralukaFan (MiralukaFan)</td>\n",
       "      <td>@PixieZelda Ester the Wonder Pig would approve!</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "      <td>3886</td>\n",
       "      <td>0</td>\n",
       "      <td>http://twitter.com/PixieZelda/statuses/1462099...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14367</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-14T17:53:05.447+0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REPLY</td>\n",
       "      <td>{entityId=10798, entityConfidence=MEDIUM, url=...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitstream</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MiralukaFan (MiralukaFan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000705381</td>\n",
       "      <td>LT - SLF Twitter Penn since 2011</td>\n",
       "      <td>2021-11-08 10:37:02.0</td>\n",
       "      <td>@angelacrazygirl @xo415 @AdamsCumbie The probl...</td>\n",
       "      <td>http://twitter.com/MissanMissen/statuses/14576...</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>positive</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>individual</td>\n",
       "      <td>2022-02-14T17:53:06.016+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MissanMissen</td>\n",
       "      <td>https://audiences.brandwatch.com/api/audiences...</td>\n",
       "      <td>{id=10980293, name=Direct sighting, displayNam...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MissanMissen (Lotta üå±)</td>\n",
       "      <td>@angelacrazygirl @xo415 @AdamsCumbie The probl...</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714</td>\n",
       "      <td>766</td>\n",
       "      <td>0</td>\n",
       "      <td>http://twitter.com/angelacrazygirl/statuses/14...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>45695</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-14T17:53:06.016+0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REPLY</td>\n",
       "      <td>{entityId=1533036, entityConfidence=HIGH, url=...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitstream</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MissanMissen (Lotta üå±)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000705381</td>\n",
       "      <td>LT - SLF Twitter Penn since 2011</td>\n",
       "      <td>2021-10-13 16:00:29.0</td>\n",
       "      <td>RT @SpottlessMarxx Shameless self-promotion vi...</td>\n",
       "      <td>http://twitter.com/Kayla01295547/statuses/1448...</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>neutral</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>individual</td>\n",
       "      <td>2022-02-14T17:53:06.866+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kayla01295547</td>\n",
       "      <td>https://audiences.brandwatch.com/api/audiences...</td>\n",
       "      <td>{id=11239953, name=Other, displayName=null, pa...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kayla01295547 (Kayla)</td>\n",
       "      <td>RT @SpottlessMarxx Shameless self-promotion vi...</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://twitter.com/SpottlessMarxx/statuses/714...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-14T17:53:06.866+0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RETWEET</td>\n",
       "      <td>{entityId=209330, entityConfidence=HIGH, url=h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitstream</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kayla01295547 (Kayla)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Query Id  ...                       Weblog Title\n",
       "0  2000705381  ...                   Midnight_Ravioli\n",
       "1  2000705381  ...  MarySwannParry (Mary Swann Parry)\n",
       "2  2000705381  ...          MiralukaFan (MiralukaFan)\n",
       "3  2000705381  ...             MissanMissen (Lotta üå±)\n",
       "4  2000705381  ...              Kayla01295547 (Kayla)\n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arcpy\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Read the data and store it in a pandas dataframe, df.  \n",
    "# A data frame is a 2-dimensional data structure.  \n",
    "    \n",
    "projectDir = r\"C:\\Users\\echoi4\\Desktop\\esterArcGISProject-20230428T013544Z-001\\esterArcGISProject\" ## Replace with your data directory\n",
    "\n",
    "\n",
    "try:\n",
    "    # When working inside ArcGIS Pro,\n",
    "    # use the project name \"CURRENT\"\n",
    "    aprx = arcpy.mp.ArcGISProject(\"CURRENT\")\n",
    "except:\n",
    "    # When working outside of ArcGIS Pro,\n",
    "    # use the project full path file name.\n",
    "    aprx = arcpy.mp.ArcGISProject(project_dir + \"/estherArcGISProject.aprx\")\n",
    "\n",
    "\n",
    "workingDir = projectDir + \"\\output\\\\\"\n",
    "visDir = workingDir + \"\\pics\\\\\"\n",
    "\n",
    "# Create output directories if they don't already exist.\n",
    "dirs = [workingDir, visDir]\n",
    "for d in dirs:\n",
    "    if not os.path.exists(d):\n",
    "        os.mkdir(d)\n",
    "\n",
    "myData = projectDir + '\\esther.csv'\n",
    "df = pd.read_csv(myData, header=5)\n",
    "\n",
    "# Print the first 5 records to get a feel for the data.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Query Id', 'Query Name', 'Date', 'Title', 'Url', 'Domain', 'Sentiment',\n",
       "       'Page Type', 'Language', 'Country Code',\n",
       "       ...\n",
       "       'Reddit Author Awarder Karma', 'Reddit Author Karma', 'Reddit Score',\n",
       "       'Region', 'Region Code', 'Root Blog Name', 'Root Post Id', 'Subreddit',\n",
       "       'Subreddit Subscribers', 'Weblog Title'],\n",
       "      dtype='object', length=105)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What fields does the data have?\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Id        Query Name        Date        Title        Url        Domain        Sentiment        Page Type        Language        Country Code        Continent Code        Continent        Country        City Code        Account Type        Added        Assignment        Author        Avatar        Category Details        Checked        City        Display URLs        Expanded URLs        Facebook Author ID        Facebook Comments        Facebook Likes        Facebook Role        Facebook Shares        Facebook Subtype        Full Name        Full Text        Gender        Hashtags        Impact        Impressions        Instagram Comments        Instagram Followers        Instagram Following        Instagram Interactions Count        Instagram Likes        Instagram Posts        Interest        Last Assignment Date        Latitude        Location Name        Longitude        Media Filter        Media URLs        Mentioned Authors        Original Url        Priority        Professions        Resource Id        Short URLs        Starred        Status        Subtype        Thread Author        Thread Created Date        Thread Entry Type        Thread Id        Thread URL        Total Monthly Visitors        Twitter Author ID        Twitter Channel Role        Twitter Followers        Twitter Following        Twitter Reply Count        Twitter Reply to        Twitter Retweet of        Twitter Retweets        Twitter Tweets        Twitter Verified        Updated        Reach (new)        Blog Name        Copyright        Engagement Type        Entity Info        Item Review        Linkedin Comments        Linkedin Engagement        Linkedin Impressions        Linkedin Likes        Linkedin Shares        Linkedin Sponsored        Linkedin Video Views        Page Type Name        Parent Blog Name        Parent Post Id        Pub Type        Publisher Sub Type        Rating        Reddit Author Awardee Karma        Reddit Author Awarder Karma        Reddit Author Karma        Reddit Score        Region        Region Code        Root Blog Name        Root Post Id        Subreddit        Subreddit Subscribers        Weblog Title        "
     ]
    }
   ],
   "source": [
    "# Print ALL the field names.\n",
    "for columnName in df.columns:\n",
    "    print(columnName,end='        ',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1121, 105)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many columns and rows does the data have?\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'United States of America', 'Australia', 'Canada',\n",
       "       'Netherlands', 'United Kingdom', 'Poland', 'Japan', 'New Zealand',\n",
       "       'Italy', 'Vietnam', 'Republic of Ireland', 'Finland', 'Croatia',\n",
       "       'Israel', 'Germany', 'The Bahamas', 'Brazil', 'Russia', 'Norway',\n",
       "       'Indonesia', 'South Africa', 'Pakistan', 'India',\n",
       "       'Republic of Serbia', 'Argentina', 'Singapore', 'Sweden',\n",
       "       'Colombia', 'Mexico', 'Gibraltar', 'Venezuela'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which countries are there in the \"Country\" field?\n",
    "# The Series method named unique returns a Numpy array containing the unique values in a series. \n",
    "df['Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'United States', 'Australia', 'Canada', 'Netherlands',\n",
       "       'United Kingdom', 'Poland', 'Japan', 'New Zealand', 'Italy',\n",
       "       'Vietnam', 'Republic of Ireland', 'Finland', 'Croatia', 'Israel',\n",
       "       'Germany', 'The Bahamas', 'Brazil', 'Russia', 'Norway',\n",
       "       'Indonesia', 'South Africa', 'Pakistan', 'India',\n",
       "       'Republic of Serbia', 'Argentina', 'Singapore', 'Sweden',\n",
       "       'Colombia', 'Mexico', 'Gibraltar', 'Venezuela'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the name in the Country column for USA to match GIS data name for USA\n",
    "df['Country'] = df['Country'].replace('United States of America','United States')\n",
    "df['Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# How many countries is that?\n",
    "# Use the built-in len method to find the length of the array of unique country names.\n",
    "print(len(df['Country'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['reddit', 'twitter', 'news', 'forum', 'review', 'tumblr', 'blog',\n",
       "       'youtube', 'instagram', 'facebook'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Page Type column indicates the detected data source (e.g., reddit, twitter, news,...)\n",
    "## Add code to determine which page types are there in the \"Page Type\" field.\n",
    "df['Page Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# How many page types are there?\n",
    "## Add code to print the number of unique page types.\n",
    "print(len(df['Page Type'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring text content \n",
    "Suppose we want to search for references to vegans or happiness in the Tweets.  We can use regular expressions to search for key words.  A _regular expression_ is a sequence of characters that specifies a search pattern in text (It's a very deep topic. This provides a gentle introduction: [How to use Regex in Pandas](https://kanoki.org/2019/11/12/how-to-use-regex-in-pandas/)).  The code below has a simple regular expression that uses | to mean 'or':\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1121\n",
      "1120\n",
      "240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16    Books that teach compassion & kindness to chil...\n",
       "19    RT @MichelleM41811 So, so, soo happy to be bac...\n",
       "34    So, so, soo happy to be back working out with ...\n",
       "36    To me, chickens hurt my heart the most. But I'...\n",
       "38    Love the sweet, contented \"smile\" on Ester the...\n",
       "Name: Full Text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regular_expression = 'happy|vegan|happiness|joy|smile'\n",
    "\n",
    "# Get a dataframe of records in which the content of the Full Text column has any of these terms. \n",
    "\n",
    "# For the moment, we only care about the column that contains the full text of the posts.\n",
    "# To make a series from a particular columns, you can specify the column name in square braces\n",
    "ft_series = df['Full Text']\n",
    "print(ft_series.size)\n",
    "\n",
    "# Prepare a dataframe that only has the non-null Tweets \n",
    "ft_series = ft_series.dropna()\n",
    "print(ft_series.size)\n",
    "\n",
    "\n",
    "# str.contains returns a Boolean series.  A series is a one dimensional data structure, like an array.\n",
    "#boolean_series = df2['Full Text'].str.contains(regular_expression, case=False)\n",
    "boolean_series = ft_series.str.contains(regular_expression, case=False)\n",
    "\n",
    "# loc is a dataframe property that allows you to access a group of rows and/or columns \n",
    "# based either on labels or a boolean array.\n",
    "# Here we're using it with the Boolean series to get the Tweets that match our terms \n",
    "# (the ones where str.contains returned True).\n",
    "joy_series = ft_series.loc[boolean_series]\n",
    "\n",
    "joy_series= joy_series.drop_duplicates()\n",
    "print(joy_series.size)\n",
    "joy_series.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract date time info. (year, month, day, or time) with the Python datetime module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "theDate = '06/14/2015  4:11:11 PM'\n",
    "# Create a string that represents the format of the date.  \n",
    "# The format code tells it where to look for each element. \n",
    "# For example, %m represents *month*, whereas %M represents *minute*.\n",
    "# A full table of format codes can be found here:  (Python strptime)[https://www.programiz.com/python-programming/datetime/strptime]\n",
    "# The datetime module's datetime class method named *strptime* stands for string parsed time.\n",
    "datem = datetime. datetime. strptime(theDate, '%m/%d/%Y %H:%M:%S %p')\n",
    "print(datem.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with dates in Pandas\n",
    "\n",
    "Dataframes have a DatetimeIndex class that makes it easy to extract the parts of a date or time from a date time stamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So many columns... does it have a Date column?\n",
    "\"Date\" in df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How about a Year column?\n",
    "\"Year\" in df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Query Id', 'Query Name', 'Date', 'Title', 'Url', 'Domain', 'Sentiment',\n",
       "       'Page Type', 'Language', 'Country Code',\n",
       "       ...\n",
       "       'Reddit Author Karma', 'Reddit Score', 'Region', 'Region Code',\n",
       "       'Root Blog Name', 'Root Post Id', 'Subreddit', 'Subreddit Subscribers',\n",
       "       'Weblog Title', 'Year'],\n",
       "      dtype='object', length=106)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Year from the Date column and make new columns for these.\n",
    "df['Year'] = pd.DatetimeIndex(df['Date']).year\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write code here to add a Month column to the dataframe (df)\n",
    "df['Month'] = pd.DatetimeIndex(df['Date']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2022, 2021, 2020, 2019, 2018, 2017, 2016, 2015, 2014, 2013, 2012],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check which years are included in the data. \n",
    "# The Series method named unique returns a Numpy array containing the unique values in a series. \n",
    "df['Year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 107)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we have years!  Let's find out how many Canadian posts there were in 2021.\n",
    "# To select the 2021 Canadian posts, we need to select rows based on two column conditions. \n",
    "#df_special = df[(df['Year'] == 2021) & (df['Country']== 'Canada')]\n",
    "\n",
    "boolean_series = (df['Year'] == 2019) & (df['Country']== 'Canada')\n",
    "df_CA_21 = df[boolean_series]\n",
    "df_CA_21.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select columns / rows to a csv to be joined with the country boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1121, 4)\n",
      "(490, 4)\n"
     ]
    }
   ],
   "source": [
    "# Select pertinent columns.\n",
    "df_small = df[['Page Type','Country', 'Year', 'Full Text']]  ## Add the month column \n",
    "\n",
    "# Print the number of rows and columns.\n",
    "print(df_small.shape)\n",
    "\n",
    "# Remove rows in which any of the values are empty.\n",
    "df_small = df_small.dropna()\n",
    "\n",
    "print(df_small.shape)\n",
    "\n",
    "smallCSV = workingDir + 'esther_reduced.csv'\n",
    "df_small.to_csv(smallCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016    100\n",
      "2017     98\n",
      "2018     68\n",
      "2015     62\n",
      "2014     60\n",
      "2019     52\n",
      "2020     28\n",
      "2021     18\n",
      "2013      3\n",
      "2022      1\n",
      "Name: Year, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Explore the reduced dataset.\n",
    "# The value_counts method provides a frequency count of values in a field.  \n",
    "# As you can see below, 2016 was a big year for Esther the Pig. \n",
    "print(df_small['Year'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016    100\n",
      "2017     98\n",
      "2018     68\n",
      "2015     62\n",
      "2014     60\n",
      "2019     52\n",
      "2020     28\n",
      "2021     18\n",
      "2013      3\n",
      "2022      1\n",
      "Name: Year, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Explore the reduced dataset.\n",
    "# Where is Esther most discussed?\n",
    "## Add code to print the frequency count for Country.  \n",
    "# As you can see below, 2016 was a big year for Esther the Pig. \n",
    "print(df_small['Year'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year:   2013\n",
      "['Australia' 'United States of America']\n",
      "Year:   2014\n",
      "['United States of America' 'United Kingdom' 'Sweden' 'Canada' 'India'\n",
      " 'Colombia' 'Mexico' 'Gibraltar' 'Venezuela']\n",
      "Year:   2015\n",
      "['United States of America' 'Australia' 'United Kingdom' 'Canada' 'Italy'\n",
      " 'Sweden']\n",
      "Year:   2016\n",
      "['Republic of Ireland' 'United Kingdom' 'Australia'\n",
      " 'United States of America' 'Italy' 'India' 'Canada' 'South Africa'\n",
      " 'Republic of Serbia' 'Finland' 'Germany' 'Croatia' 'New Zealand'\n",
      " 'Argentina' 'Singapore']\n",
      "Year:   2017\n",
      "['United States of America' 'Australia' 'Canada' 'Israel' 'Brazil'\n",
      " 'Russia' 'United Kingdom' 'Norway' 'Indonesia' 'South Africa' 'Pakistan']\n",
      "Year:   2018\n",
      "['United States of America' 'Canada' 'Croatia' 'Australia'\n",
      " 'United Kingdom' 'Japan' 'Israel' 'Republic of Ireland' 'Germany'\n",
      " 'The Bahamas']\n",
      "Year:   2019\n",
      "['United States of America' 'Italy' 'Canada' 'Japan' 'Vietnam'\n",
      " 'United Kingdom' 'Republic of Ireland' 'Australia' 'Finland']\n",
      "Year:   2020\n",
      "['Canada' 'United States of America' 'Australia' 'Poland' 'Japan'\n",
      " 'United Kingdom' 'New Zealand']\n",
      "Year:   2021\n",
      "['Australia' 'Canada' 'Netherlands' 'United Kingdom'\n",
      " 'United States of America']\n",
      "Year:   2022\n",
      "['United States of America']\n"
     ]
    }
   ],
   "source": [
    "# Explore the reduced dataset.\n",
    "# Which countries have postings each year? \n",
    "for val in sorted(df_small['Year'].unique()):\n",
    "    # selecting rows based on condition\n",
    "    rslt_df = df_small[df_small['Year'] == val]\n",
    "    print(f'Year:   {val}')\n",
    "    print(rslt_df['Country'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a copy of the worldwide countries dataset\n",
    "\n",
    "Other data will be joined to this, so we want to preserve the original before modifying the table.\n",
    "\n",
    "Data source: \n",
    "[ArcGIS Hub World Countries Generalized] (https://hub.arcgis.com/datasets/2b93b06dc0dc4e809d3c8db5cb96ba69_0/explore?location=-0.101905%2C0.000000%2C2.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, April 28, 2023 5:19:35 AM\",\"Succeeded at Friday, April 28, 2023 5:19:35 AM (Elapsed Time: 0.32 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\echoi4\\\\Desktop\\\\esterArcGISProject-20230428T013544Z-001\\\\esterArcGISProject\\\\output\\\\worldEsther.shp'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arcpy\n",
    "arcpy.env.workspace = projectDir + r'esterArcGISProject.gdb'\n",
    "arcpy.env.overwriteOutput = True\n",
    "worldData = 'world_countries'\n",
    "worldDataCopy = workingDir + 'worldEsther.shp'\n",
    "arcpy.CopyFeatures_management(worldData, worldDataCopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'esther'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a the base name (without the extention) of the input data.  We'll use this to name files in the next part.\n",
    "baseName = os.path.basename(myData)\n",
    "baseName = os.path.splitext(baseName)[0]\n",
    "baseName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a table for each time step and join the tables with the GIS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in 2013: 3\n",
      "Year:   2013\n",
      "['Australia' 'United States of America']\n",
      "Number of records in 2014: 60\n",
      "Year:   2014\n",
      "['United States of America' 'United Kingdom' 'Sweden' 'Canada' 'India'\n",
      " 'Colombia' 'Mexico' 'Gibraltar' 'Venezuela']\n",
      "Number of records in 2015: 62\n",
      "Year:   2015\n",
      "['United States of America' 'Australia' 'United Kingdom' 'Canada' 'Italy'\n",
      " 'Sweden']\n",
      "Number of records in 2016: 100\n",
      "Year:   2016\n",
      "['Republic of Ireland' 'United Kingdom' 'Australia'\n",
      " 'United States of America' 'Italy' 'India' 'Canada' 'South Africa'\n",
      " 'Republic of Serbia' 'Finland' 'Germany' 'Croatia' 'New Zealand'\n",
      " 'Argentina' 'Singapore']\n",
      "Number of records in 2017: 98\n",
      "Year:   2017\n",
      "['United States of America' 'Australia' 'Canada' 'Israel' 'Brazil'\n",
      " 'Russia' 'United Kingdom' 'Norway' 'Indonesia' 'South Africa' 'Pakistan']\n",
      "Number of records in 2018: 68\n",
      "Year:   2018\n",
      "['United States of America' 'Canada' 'Croatia' 'Australia'\n",
      " 'United Kingdom' 'Japan' 'Israel' 'Republic of Ireland' 'Germany'\n",
      " 'The Bahamas']\n",
      "Number of records in 2019: 52\n",
      "Year:   2019\n",
      "['United States of America' 'Italy' 'Canada' 'Japan' 'Vietnam'\n",
      " 'United Kingdom' 'Republic of Ireland' 'Australia' 'Finland']\n",
      "Number of records in 2020: 28\n",
      "Year:   2020\n",
      "['Canada' 'United States of America' 'Australia' 'Poland' 'Japan'\n",
      " 'United Kingdom' 'New Zealand']\n",
      "Number of records in 2021: 18\n",
      "Year:   2021\n",
      "['Australia' 'Canada' 'Netherlands' 'United Kingdom'\n",
      " 'United States of America']\n",
      "Number of records in 2022: 1\n",
      "Year:   2022\n",
      "['United States of America']\n"
     ]
    }
   ],
   "source": [
    "# Create an empty dictionary to store the number of records per year.\n",
    "yearly_count = {}\n",
    "\n",
    "# For each year in the reduced dataset, create a csv file.\n",
    "\n",
    "for yr in sorted(df_small['Year'].unique()):\n",
    "    # Select rows based on the year\n",
    "    rslt_df = df_small[df_small['Year'] == yr]\n",
    "    print(f\"Number of records in {yr}: {len(rslt_df)}\")\n",
    "    yearly_count[yr] = len(rslt_df)\n",
    "\n",
    "    # Prepare an output name\n",
    "    annualCSV = workingDir + f'{baseName}{yr}.csv'\n",
    "    \n",
    "    # Write the data frame to csv\n",
    "    rslt_df.to_csv(annualCSV)\n",
    "    \n",
    "    print(f'Year:   {yr}')\n",
    "    print(rslt_df['Country'].unique())\n",
    "    \n",
    "    # Join the data\n",
    "    joinedData = arcpy.management.AddJoin(\n",
    "        in_layer_or_view = worldDataCopy, \n",
    "        in_field = 'COUNTRY', \n",
    "        join_table = annualCSV, \n",
    "        join_field = 'Country', \n",
    "    join_type = 'KEEP_COMMON')\n",
    "    \n",
    "    curData = workingDir + f'{baseName}{yr}.shp'\n",
    "    try:\n",
    "        arcpy.CopyFeatures_management(joinedData, curData)\n",
    "    except:\n",
    "        print(\"File already exists.  New copy not created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove layers that have been added to the map during processing\n",
    "This will allow us to control which layers are visible for screenshot capturing.\n",
    "The pictures could have been captured while the data were being created, but\n",
    "these steps are separated to make them easier to distinguish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esther2022\n",
      "worldEsther_Layer9\n",
      "esther2021\n",
      "worldEsther_Layer8\n",
      "esther2020\n",
      "worldEsther_Layer7\n",
      "esther2019\n",
      "worldEsther_Layer6\n",
      "esther2018\n",
      "worldEsther_Layer5\n",
      "esther2017\n",
      "worldEsther_Layer4\n",
      "esther2016\n",
      "worldEsther_Layer3\n",
      "esther2015\n",
      "worldEsther_Layer2\n",
      "esther2014\n",
      "worldEsther_Layer1\n",
      "esther2013\n",
      "worldEsther_Layer\n",
      "worldEsther\n",
      "Moth2021\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "The attribute 'name' is not supported on this instance of Layer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "In  \u001b[0;34m[33]\u001b[0m:\nLine \u001b[0;34m15\u001b[0m:    \u001b[36mprint\u001b[39;49;00m (i.name)\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\arcobjects\\_base.py\u001b[0m, in \u001b[0;32m_get\u001b[0m:\nLine \u001b[0;34m93\u001b[0m:    \u001b[34mraise\u001b[39;49;00m \u001b[36mAttributeError\u001b[39;49;00m(\n",
      "\u001b[0;31mAttributeError\u001b[0m: The attribute 'name' is not supported on this instance of Layer.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# aprx is the ArcGIS project object\n",
    "\n",
    "# Get a list of maps in this project.\n",
    "myMap = aprx.listMaps('Map')[0]\n",
    "layers = myMap.listLayers()\n",
    "layer_object = layers[0]\n",
    "count = 0 \n",
    "while \"Worldwide\" not in layer_object.name and count < len(layers):\n",
    "    print(layer_object.name)\n",
    "    myMap.removeLayer(layer_object)\n",
    "    count = count + 1\n",
    "    layer_object = layers[count]\n",
    "    \n",
    "for i in layers:\n",
    "    print (i.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create map layers and take screenshots\n",
    "\n",
    "We'll do this by looping through the years. Earlier, we created a shapefile for each year.  Now we'll make a layer for each shapefile.   We'll add it to the map, capture a screenshot (a png image), and turn then that layer's visibility off, so that we can do the same again with the next shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legend\n",
      "Text\n",
      "North Arrow\n",
      "Map Frame\n",
      "esther2013\n",
      "esther2013:True\n",
      "esther2014\n",
      "esther2014:True\n",
      "esther2015\n",
      "esther2015:True\n",
      "esther2016\n",
      "esther2016:True\n",
      "esther2017\n",
      "esther2017:True\n",
      "esther2018\n",
      "esther2018:True\n",
      "esther2019\n",
      "esther2019:True\n",
      "esther2020\n",
      "esther2020:True\n",
      "esther2021\n",
      "esther2021:True\n",
      "esther2022\n",
      "esther2022:True\n"
     ]
    }
   ],
   "source": [
    "# aprx is the ArcGIS project object\n",
    "\n",
    "# Get a list of maps in this project.\n",
    "myMap = aprx.listMaps('Map')[0]\n",
    "\n",
    "custom_layout = aprx.listLayouts(\"*surround*\")[0]\n",
    "for elem in custom_layout.listElements():\n",
    "    print(elem.name)\n",
    "    if \"Text\" in elem.name:\n",
    "        textbox = elem\n",
    "\n",
    "\n",
    "RGBs = [[190, 210, 255, 60], [245, 122, 122, 60], [255, 255, 0, 60]]\n",
    "\n",
    "# For each year in the data, add a layer and export an image of it.\n",
    "for yr in sorted(df_small['Year'].unique()):\n",
    "\n",
    "    # Get the name of the shapefile associated with the current year. \n",
    "    curData = workingDir + f'{baseName}{yr}.shp'\n",
    "    \n",
    "    # Add the shapefile as a layer on the map.\n",
    "    myMap.addDataFromPath(curData)\n",
    "    # Set the text string to current year\n",
    "    textbox.text = yr\n",
    "    \n",
    "    # Now we need the layer object associated with our new layer. \n",
    "    # This gives access to the symbology properties of the layer.  \n",
    "    # Get a list of layor objects for the layers on this map.\n",
    "    layerObjects = myMap.listLayers()\n",
    "    \n",
    "    # Get the first one (the most recently added to the map)\n",
    "    lay = layerObjects[0]\n",
    "\n",
    "    print(lay.name)\n",
    "    \n",
    "    sym = lay.symbology\n",
    "    \n",
    "    # Set an RGB color for the layer.  \n",
    "    # Provide the colors as a list of numbers (red, green, and blue, plus alpha for transparency).\n",
    "    # E.g., [190, 210, 255, 60] is a purple with opacity of 60%.\n",
    "    theColor = [245, 122, 122, 100]  # pink with no transparency\n",
    "    sym.renderer.symbol.color = {'RGB': theColor}  \n",
    "\n",
    "    ## As an alternative to specifying RGB values, you can apply symbology from the gallery.\n",
    "    # Try something you like.  See the named_symbology_examples.png for other names \n",
    "    # or look at the choices in ArcGIS Pro to see more.\n",
    "    # sym.renderer.symbol.applySymbolFromGallery('Mangrove')\n",
    "\n",
    "    ## Experiment with the outline by uncommenting the code below\n",
    "    # sym.renderer.symbol.outlineColor = {'CMYK' : [25, 50, 75, 25, 100]}\n",
    "    lay.symbology = sym\n",
    "    #if theMonth == 12:\n",
    "    #    myMap.defaultView.zoomToAllLayers()\n",
    "    print ('{}:{}'.format(lay.name, lay.visible))\n",
    "    outPic = visDir+f'{baseName}{str(yr).zfill(2)}.png'\n",
    "    #myMap.defaultView.exportToPNG(outPic, width=800, height=600)\n",
    "    custom_layout.exportToPNG(outPic)\n",
    "    lay.visible = False\n",
    "    \n",
    "    del lay\n",
    "del myMap\n",
    "del aprx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creat an animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\echoi4\\Desktop\\esterArcGISProject-20230428T013544Z-001\\esterArcGISProject\\output\\\\pics\\/movie.gif created using 10 maps!\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "images = []\n",
    "import os\n",
    "mapPics = os.listdir(visDir)\n",
    "\n",
    "movieName = visDir + '/movie.gif'\n",
    "if os.path.exists(movieName):\n",
    "    os.remove(movieName)\n",
    "\n",
    "for pic in mapPics:\n",
    "    if pic.endswith(\"png\"):\n",
    "        images.append(imageio.imread(visDir + pic))\n",
    "\n",
    "\n",
    "imageio.mimsave(movieName, images, duration=0.8)\n",
    "image_count = len(images)\n",
    "print('{} created using {} maps!'.format( movieName, image_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['esther2013.png', 'esther2014.png', 'esther2015.png', 'esther2016.png', 'esther2017.png', 'esther2018.png', 'esther2019.png', 'esther2020.png', 'esther2021.png', 'esther2022.png', 'Moth.html']\n"
     ]
    }
   ],
   "source": [
    "print(mapPics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an html display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = \"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "div.gallery {\n",
    "  border: 1px solid #ccc;\n",
    "}\n",
    "\n",
    "div.gallery:hover {\n",
    "  border: 1px solid #777;\n",
    "}\n",
    "\n",
    "div.gallery img {\n",
    "  width: 100%;\n",
    "  height: auto;\n",
    "}\n",
    "\n",
    "div.desc {\n",
    "  padding: 15px;\n",
    "  text-align: center;\n",
    "}\n",
    "\n",
    "* {\n",
    "  box-sizing: border-box;\n",
    "}\n",
    "\n",
    ".responsive {\n",
    "  padding: 0 6px;\n",
    "  float: left;\n",
    "  width: 24.99999%;\n",
    "}\n",
    "\n",
    "@media only screen and (max-width: 700px) {\n",
    "  .responsive {\n",
    "    width: 49.99999%;\n",
    "    margin: 6px 0;\n",
    "  }\n",
    "}\n",
    "\n",
    "@media only screen and (max-width: 500px) {\n",
    "  .responsive {\n",
    "    width: 100%;\n",
    "  }\n",
    "}\n",
    "\n",
    ".clearfix:after {\n",
    "  content: \"\";\n",
    "  display: table;\n",
    "  clear: both;\n",
    "}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\"\"\" \n",
    "\n",
    "bodyContent = f\"\"\"<h2>{baseName.title()} Posts Over {image_count} Years </h2>\n",
    "<h4>Author: Grace Choi</h4>\n",
    "<h4>Data source: {baseName} Esther the Wonder Pig</h4>\"\"\"\n",
    "\n",
    "mapPics = os.listdir(visDir)\n",
    "\n",
    "mapPics = [picName for picName in mapPics if picName.endswith('.png') ]\n",
    "\n",
    "for pic in mapPics:\n",
    "    dateVal = os.path.splitext(pic)[0]\n",
    "    dateVal = dateVal.replace(baseName,'')\n",
    "    dateVal = int(dateVal)\n",
    "    bodyContent = bodyContent + f\"\"\"<div class=\"responsive\"><div class=\"gallery\">\n",
    "  <a target=\"_blank\" href={pic}>\n",
    "    <img src={pic} alt=\"{os.path.splitext(pic)[0]}\" width=\"800\" height=\"600\">\n",
    "  </a>\n",
    "  <div class=\"desc\">{yearly_count[dateVal]} {baseName.title()} post(s) in {dateVal}</div>\n",
    "</div></div>\"\"\"\n",
    "\n",
    "# Add movie\n",
    "movieName = os.path.basename(movieName)\n",
    "bodyContent = bodyContent + f\"\"\"<div class=\"responsive\"><div class=\"gallery\">\n",
    "  <a target=\"_blank\" href={movieName}>\n",
    "    <img src={movieName} alt=\"animation\" width=\"800\" height=\"600\">\n",
    "  </a>\n",
    "  <div class=\"desc\">{baseName.title()} posts over time.</div>\n",
    "</div></div>\"\"\"\n",
    "\n",
    "\n",
    "footer = \"\"\"</body>\n",
    "</html>\"\"\"\n",
    "\n",
    "html_file_name = visDir + f'{baseName}.html'\n",
    "\n",
    "with open( html_file_name,'w') as outFileObject:\n",
    "  outFileObject.write(header)\n",
    "  outFileObject.write(bodyContent)\n",
    "  outFileObject.write(footer)\n",
    "os.startfile(html_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0515d880074d3a778d90148b56f6d3aa63d459907926b681bcdb25236e1288ae"
  },
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
